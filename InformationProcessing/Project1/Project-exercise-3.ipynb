{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeyPhrase extraction\n",
    "* Use SemEval 2010 dataset - [H49](https://github.com/boudinfl/ake-datasets/blob/master/datasets/SemEval-2010/train/H-49.xml) dataset for TF-IDF vectorization\n",
    "* Use SemEval 2010 dataset - [H7](https://github.com/boudinfl/ake-datasets/blob/master/datasets/SemEval-2010/test/H-7.xml) for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import operator\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(directory):\n",
    "    docs = {}\n",
    "    for doc_path in tqdm(glob(f'{directory}/*.xml')):\n",
    "        doc = ElementTree.parse(doc_path)\n",
    "        sentences = []\n",
    "        for sentence in doc.find('document').find('sentences').findall('sentence'):\n",
    "            sentences.append(' '.join([token.find('lemma').text.lower() + '~' + token.find('POS').text\n",
    "                                       for token in sentence.find('tokens').findall('token')]))\n",
    "\n",
    "        docs[doc_path.split('/')[-1].split('.')[0]] = '\\n'.join(sentences)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c612627b83740d2ab94e20715a6d5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289b2e7564a840779b10eff876659f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(144, 100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read('ake-datasets/datasets/SemEval-2010/train')\n",
    "test_sentences = read('ake-datasets/datasets/SemEval-2010/test')\n",
    "len(train_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'(((\\w+~JJ)* (\\w+~NN)+ (\\w+~IN))?(\\w+~JJ)+ (\\w+~NN)+)+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_candidates = {doc_id: [candidate[0] for candidate in re.findall(pattern, doc)] for doc_id, doc in train_sentences.items()}\n",
    "train_candidates = {doc_id: [' '.join([w.split('~')[0] for w in candidate.split()]) for candidate in candidates] for doc_id, candidates in train_candidates.items()}\n",
    "train_sentences = {doc_id: ' '.join([w.split('~')[0] for w in sentences.split()]) for doc_id, sentences in train_sentences.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candidates = {doc_id: [candidate[0] for candidate in re.findall(pattern, doc)] for doc_id, doc in test_sentences.items()}\n",
    "test_candidates = {doc_id: [' '.join([w.split('~')[0] for w in candidate.split()]) for candidate in candidates] for doc_id, candidates in test_candidates.items()}\n",
    "test_sentences = {doc_id: ' '.join([w.split('~')[0] for w in sentences.split()]) for doc_id, sentences in test_sentences.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 3))\n",
    "trainvec = vectorizer.fit_transform(train_sentences.values())\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ake-datasets/datasets/SemEval-2010/references/test.author.stem.json', 'r') as f:\n",
    "    target = json.load(f)\n",
    "    target = {doc_name: [k[0] for k in keyphrases] for doc_name, keyphrases in target.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imag retriev', 'activ learn', 'relev feedback']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['H-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['optimal design',\n",
       " 'powerful technique',\n",
       " 'irrelevant image',\n",
       " 'informative one',\n",
       " 'unlabeled image',\n",
       " 'active learning',\n",
       " 'optimal design',\n",
       " 'square error',\n",
       " 'geometrical structure',\n",
       " 'geometrical structure',\n",
       " 'experimental design',\n",
       " 'experimental result',\n",
       " 'many machine',\n",
       " 'unlabeled datum',\n",
       " 'unlabeled sample',\n",
       " 'active learning',\n",
       " 'overall cost',\n",
       " 'real world',\n",
       " 'active learning',\n",
       " 'based image',\n",
       " 'based image',\n",
       " 'substantial interest',\n",
       " 'last decade',\n",
       " 'fast growth',\n",
       " 'digital image',\n",
       " 'efficient search',\n",
       " 'low level',\n",
       " 'visual feature',\n",
       " 'low level',\n",
       " 'high level',\n",
       " 'semantic concept',\n",
       " 'semantic gap',\n",
       " 'current relevance',\n",
       " 'top image',\n",
       " 'separate image',\n",
       " 'informative one',\n",
       " 'top image',\n",
       " 'standard classification',\n",
       " 'negative example',\n",
       " 'standard classification',\n",
       " 'active learning',\n",
       " 'active learning',\n",
       " 'active learning',\n",
       " 'active learning',\n",
       " 'active learning',\n",
       " 'unlabeled image',\n",
       " 'maximal refinement',\n",
       " 'major disadvantage',\n",
       " 'active learning',\n",
       " 'labeled image',\n",
       " 'other svm',\n",
       " 'active learning',\n",
       " 'experimental design',\n",
       " 'experimental design',\n",
       " 'parameterized model',\n",
       " 'experimental design',\n",
       " 'experimental design',\n",
       " 'active learning',\n",
       " 'experimental design',\n",
       " 'objective function',\n",
       " 'experimental design',\n",
       " 'supervised learning',\n",
       " 'active learning',\n",
       " 'optimal design',\n",
       " 'experimental design',\n",
       " 'unmeasured point',\n",
       " 'new loss',\n",
       " 'other word',\n",
       " 'same label',\n",
       " 'informative datum',\n",
       " 'informative image',\n",
       " 'brief description',\n",
       " 'related work',\n",
       " 'optimal design',\n",
       " 'art algorithm',\n",
       " 'experimental result',\n",
       " 'future work',\n",
       " 'related work',\n",
       " 'experimental design',\n",
       " 'brief description',\n",
       " 'active learning',\n",
       " 'generic problem',\n",
       " 'active learning',\n",
       " 'informative point',\n",
       " 'other word',\n",
       " 'experimental design',\n",
       " 'linear regression',\n",
       " 'independent variable',\n",
       " 'unknown error',\n",
       " 'different observation',\n",
       " 'equal variance',\n",
       " 'markov theorem',\n",
       " 'common scalar',\n",
       " 'experimental design',\n",
       " 'optimal design',\n",
       " 'optimal design',\n",
       " 'optimal design',\n",
       " 'optimal design',\n",
       " 'recent work',\n",
       " 'experimental design',\n",
       " 'traditional approach',\n",
       " 'expected error',\n",
       " 'unmeasured sample',\n",
       " 'active learning',\n",
       " 'optimal design',\n",
       " 'efficient use',\n",
       " 'many machine',\n",
       " 'new loss',\n",
       " 'geometrical structure',\n",
       " 'passive learning',\n",
       " 'informative datum',\n",
       " 'symmetric weight',\n",
       " 'heavy penalty',\n",
       " 'many choice',\n",
       " 'simple definition',\n",
       " 'diagonal matrix',\n",
       " 'spectral graph',\n",
       " 'algebraic step',\n",
       " 'full rank',\n",
       " 'optimal estimate',\n",
       " 'stable solution',\n",
       " 'common way',\n",
       " 'posed problem',\n",
       " 'variable x',\n",
       " 'predictive error',\n",
       " 'complete data',\n",
       " 'laplacian optimality',\n",
       " 'optimal design',\n",
       " 'experimental design',\n",
       " 'optimal design',\n",
       " 'linear function',\n",
       " 'intrinsic geometry',\n",
       " 'experimental design',\n",
       " 'experimental design',\n",
       " 'definite mercer',\n",
       " 'unique rkhs',\n",
       " 'linear combination',\n",
       " 'such function',\n",
       " 'orthogonal complement',\n",
       " 'orthogonal decomposition',\n",
       " 'direct way',\n",
       " 'optimal design',\n",
       " 'linear kernel',\n",
       " 'greedy approach',\n",
       " 'inner product',\n",
       " 'functional space',\n",
       " 'based image',\n",
       " 'optimal design',\n",
       " 'brief description',\n",
       " 'low level',\n",
       " 'visual feature',\n",
       " 'level image',\n",
       " 'level image',\n",
       " 'crucial problem',\n",
       " 'visual feature',\n",
       " 'visual feature',\n",
       " 'accurate image',\n",
       " 'special application',\n",
       " 'dimensional color',\n",
       " 'dimensional color',\n",
       " 'compact form',\n",
       " 'local fourier',\n",
       " 'characteristic map',\n",
       " 'different aspect',\n",
       " 'second moment',\n",
       " 'natural color',\n",
       " 'important technique',\n",
       " 'low level',\n",
       " 'visual feature',\n",
       " 'high level',\n",
       " 'semantic concept',\n",
       " 'different dimension',\n",
       " 'line learning',\n",
       " 'typical retrieval',\n",
       " 'defined distance',\n",
       " 'top image',\n",
       " 'optimal design',\n",
       " 'second step',\n",
       " 'informative image',\n",
       " 'computational complexity',\n",
       " 'unlabeled image',\n",
       " 'previous iteration',\n",
       " 'experimental result',\n",
       " 'large image',\n",
       " 'active learning',\n",
       " 'active learning',\n",
       " 'standard classification',\n",
       " 'supervised learning',\n",
       " 'unlabeled image',\n",
       " 'ordinary svm',\n",
       " 'ordinary regression',\n",
       " 'same graph',\n",
       " 'synthetic example',\n",
       " 'synthetic example',\n",
       " 'synthetic example',\n",
       " 'big circle',\n",
       " 'big circle',\n",
       " 'small circle',\n",
       " 'original data',\n",
       " 'experimental design',\n",
       " 'semantic category',\n",
       " 'heterogeneous image',\n",
       " 'dimensional vector',\n",
       " 'reliable way',\n",
       " 'other algorithm',\n",
       " 'different aspect',\n",
       " 'experimental design',\n",
       " 'scope curve',\n",
       " 'ranked image',\n",
       " 'relevant image',\n",
       " 'active learning',\n",
       " 'original data',\n",
       " 'svmactive algorithm',\n",
       " 'scope curve',\n",
       " 'various scope',\n",
       " 'overall performance',\n",
       " 'other hand',\n",
       " 'particular value',\n",
       " 'real world',\n",
       " 'such environment',\n",
       " 'fold cross',\n",
       " 'whole image',\n",
       " 'equal size',\n",
       " 'query set',\n",
       " 'precisionscope curve',\n",
       " 'fold cross',\n",
       " 'automatic feedback',\n",
       " 'previous iteration',\n",
       " 'later selection',\n",
       " 'automatic relevance',\n",
       " 'automatic relevance',\n",
       " 'irrelevant image',\n",
       " 'real world',\n",
       " 'ranked image',\n",
       " 'irrelevant image',\n",
       " 'real world',\n",
       " 'many round',\n",
       " 'first round',\n",
       " 'scope curve',\n",
       " 'different algorithm',\n",
       " 'euclidean distance',\n",
       " 'dimensional space',\n",
       " 'active learning',\n",
       " 'informative image',\n",
       " 'informative image',\n",
       " 'scope curve',\n",
       " 'different algorithm',\n",
       " 'entire scope',\n",
       " 'first round',\n",
       " 'svmactive algorithm',\n",
       " 'ordinary svm',\n",
       " 'initial classifier',\n",
       " 'first round',\n",
       " 'standard svm',\n",
       " 'initial classifier',\n",
       " 'entire scope',\n",
       " 'efficient use',\n",
       " 'unlabeled image',\n",
       " 'ordinary regression',\n",
       " 'corresponding precision',\n",
       " 'unlabeled image',\n",
       " 'unlabeled image',\n",
       " 'geometrical structure',\n",
       " 'real world',\n",
       " 'many relevance',\n",
       " 'several experiment',\n",
       " 'interesting point',\n",
       " 'active learning',\n",
       " 'significant increase',\n",
       " 'active learning',\n",
       " 'real world',\n",
       " 'manual labeling',\n",
       " 'active learning',\n",
       " 'informative sample',\n",
       " 'supervised learning',\n",
       " 'unlabeled sample',\n",
       " 'active learning',\n",
       " 'supervised learning',\n",
       " 'standard regression',\n",
       " 'informative sample',\n",
       " 'objective function',\n",
       " 'active learning',\n",
       " 'supervised learning',\n",
       " 'optimal classifier',\n",
       " 'active learning',\n",
       " 'optimal design',\n",
       " 'effective relevance',\n",
       " 'objective function',\n",
       " 'empirical error',\n",
       " 'geometrical structure',\n",
       " 'experimental design',\n",
       " 'informative image',\n",
       " 'unlabeled image',\n",
       " 'experimental result',\n",
       " 'active learning',\n",
       " 'supervised learning',\n",
       " 'domain image',\n",
       " 'challenging domain',\n",
       " 'large amount',\n",
       " 'computational complexity',\n",
       " 'crucial issue',\n",
       " 'primary interest',\n",
       " 'large amount',\n",
       " 'limited sample']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_candidates['H-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyphrases(vec, feature_names, nb_keywords=5):\n",
    "    feature_index = vec.nonzero()[1]\n",
    "    tfidf_scores = zip(feature_index, [vec[0, x] for x in feature_index])\n",
    "    # Scale scores by n-gram length\n",
    "    scores = {feature_names[i]: s * len(feature_names[i].split()) for i, s in tfidf_scores}\n",
    "    scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[:nb_keywords]\n",
    "    return [keyphrase for keyphrase, score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for doc_id, doc in test_sentences.items():\n",
    "    vec = vectorizer.transform(test_candidates[doc_id])\n",
    "    keyphrases = extract_keyphrases(vec, feature_names=feature_names, nb_keywords=5)\n",
    "    predictions[doc_id] = keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['generation', 'fast', 'efficient', 'storage', 'secondary'],\n",
       " ['web summari', 'snippet gener', 'document cach'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['H-12'], target['H-12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-1   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-14  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-17  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-18  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-19  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "C-20  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-22  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-23  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-27  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-28  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-29  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-3   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-30  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-31  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-32  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-33  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-34  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-36  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-38  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-4   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-40  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-6   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-8   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-86  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-9   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-10  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-11  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-12  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-13  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-14  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-16  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-17  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-18  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-19  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-2   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-20  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-21  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-24  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-25  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-26  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-29  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-3   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-30  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-31  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-32  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-4   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-5   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-7   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-8   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-9   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-1   -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "I-10  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-11  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-12  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-14  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-15  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-16  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-18  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-19  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-20  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-21  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-22  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-26  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-29  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-30  -> Precision: 0.20 Recall: 0.20 F1: 0.20 precision@5: 0.20\n",
      "I-31  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-32  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-33  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-34  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-35  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-4   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-5   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-6   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-7   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-9   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-1   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-10  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-11  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-13  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-14  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-15  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "J-17  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-18  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-2   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-20  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-21  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-22  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-23  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "J-25  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-26  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-27  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-28  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-3   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-30  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-31  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-32  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-4   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-7   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-8   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-9   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "\n",
      "--------------Mean-------------\n",
      "Precision: 0.01 Recall: 0.02 F1: 0.01   precision@5: 0.01\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, precision_5 = [], [], [], []\n",
    "for doc_id in sorted(predictions.keys()):\n",
    "    p = set(predictions[doc_id])\n",
    "    t = set(target[doc_id])\n",
    "    at_5 = set(target[doc_id][:5])\n",
    "\n",
    "    # We always predict 5 keywords\n",
    "    precision.append(len(p.intersection(t)) / len(p))\n",
    "    recall.append(len(p.intersection(t)) / len(t))\n",
    "    f1.append(0 if precision[-1] + recall[-1] == 0 else 2 * precision[-1] * recall[-1] / (precision[-1] + recall[-1]))\n",
    "    precision_5.append(len(p.intersection(at_5)) / len(p))\n",
    "    print(f'{doc_id:5} -> Precision: {precision[-1]:.2f} Recall: {recall[-1]:.2f} F1: {f1[-1]:.2f} precision@5: {precision_5[-1]:.2f}')\n",
    "\n",
    "print()\n",
    "print('--------------Mean-------------')\n",
    "print(f'Precision: {np.mean(precision):.2f} Recall: {np.mean(recall):.2f} F1: {np.mean(f1):.2f}   precision@5: {np.mean(precision_5):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
