{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeyPhrase extraction\n",
    "* Use SemEval 2010 dataset - [H49](https://github.com/boudinfl/ake-datasets/blob/master/datasets/SemEval-2010/train/H-49.xml) dataset for TF-IDF vectorization\n",
    "* Use SemEval 2010 dataset - [H7](https://github.com/boudinfl/ake-datasets/blob/master/datasets/SemEval-2010/test/H-7.xml) for inference\n",
    "* Evaluation of the results shows precisoin, recall, f1, and precision@5 per each document and also the mean of those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(directory):\n",
    "    docs = {}\n",
    "    for doc_path in tqdm(glob(f'{directory}/*.xml')):\n",
    "        doc = ElementTree.parse(doc_path)\n",
    "        sentences = []\n",
    "        for sentence in doc.find('document').find('sentences').findall('sentence'):\n",
    "            sentences.append(' '.join([token.find('lemma').text.lower() \n",
    "                                       for token in sentence.find('tokens').findall('token')]))\n",
    "\n",
    "        docs[doc_path.split('/')[-1].split('.')[0]] = '\\n'.join(sentences)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2448cefe43b402cbdeb0c449a587dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sentences = read('ake-datasets/datasets/SemEval-2010/train')\n",
    "test_sentences = read('ake-datasets/datasets/SemEval-2010/test')\n",
    "len(train_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 3))\n",
    "trainvec = vectorizer.fit_transform(train_sentences.values())\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ake-datasets/datasets/SemEval-2010/references/test.author.stem.json', 'r') as f:\n",
    "    target = json.load(f)\n",
    "    target = {doc_name: [k[0] for k in keyphrases] for doc_name, keyphrases in target.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target['H-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_sentences['H-11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyphrases(vec, feature_names, nb_keywords=5):\n",
    "    feature_index = vec.nonzero()[1]\n",
    "    tfidf_scores = zip(feature_index, [vec[0, x] for x in feature_index])\n",
    "    # Scale scores by n-gram length\n",
    "    scores = {feature_names[i]: s * len(feature_names[i].split()) for i, s in tfidf_scores}\n",
    "    scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[:nb_keywords]\n",
    "    return [keyphrase for keyphrase, score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for doc_id, doc in test_sentences.items():\n",
    "    vec = vectorizer.transform([doc])[0]\n",
    "    keyphrases = extract_keyphrases(vec, feature_names=feature_names, nb_keywords=5)\n",
    "    predictions[doc_id] = keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['H-11'], target['H-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precision, recall, f1, precision_5 = [], [], [], []\n",
    "for doc_id in sorted(predictions.keys()):\n",
    "    p = set(predictions[doc_id])\n",
    "    t = set(target[doc_id])\n",
    "    at_5 = set(target[doc_id][:5])\n",
    "\n",
    "    # We always predict 5 keywords\n",
    "    precision.append(len(p.intersection(t)) / len(p))\n",
    "    recall.append(len(p.intersection(t)) / len(t))\n",
    "    f1.append(0 if precision[-1] + recall[-1] == 0 else 2 * precision[-1] * recall[-1] / (precision[-1] + recall[-1]))\n",
    "    precision_5.append(len(p.intersection(at_5)) / len(p))\n",
    "    print(f'{doc_id:5} -> Precision: {precision[-1]:.2f} Recall: {recall[-1]:.2f} F1: {f1[-1]:.2f} precision@5: {precision_5[-1]:.2f}')\n",
    "\n",
    "print()\n",
    "print('--------------Mean-------------')\n",
    "print(f'Precision: {np.mean(precision):.2f} Recall: {np.mean(recall):.2f} F1: {np.mean(f1):.2f}   precision@5: {np.mean(precision_5):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
