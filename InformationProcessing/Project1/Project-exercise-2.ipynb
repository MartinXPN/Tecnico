{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeyPhrase extraction\n",
    "* Use SemEval 2010 dataset - [train](https://github.com/boudinfl/ake-datasets/blob/master/datasets/SemEval-2010/train/) dataset for TF-IDF vectorization\n",
    "* Use SemEval 2010 dataset - [test](https://github.com/boudinfl/ake-datasets/blob/master/datasets/SemEval-2010/test/) for inference\n",
    "* Evaluation of the results shows precisoin, recall, f1, and precision@5 per each document and also the mean of those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "sno = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(directory):\n",
    "    docs = {}\n",
    "    for doc_path in tqdm(glob(f'{directory}/*.xml')):\n",
    "        doc = ElementTree.parse(doc_path)\n",
    "        sentences = []\n",
    "        for sentence in doc.find('document').find('sentences').findall('sentence'):\n",
    "            sentences.append(' '.join([token.find('lemma').text.lower() \n",
    "                                       for token in sentence.find('tokens').findall('token')]))\n",
    "\n",
    "        docs[doc_path.split('/')[-1].split('.')[0]] = '\\n'.join(sentences)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459d3323dfaa42ffb4c98b929676ad22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=144), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b532b8d88a7d456da24dbeab7f252b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(144, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read('ake-datasets/datasets/SemEval-2010/train')\n",
    "test_sentences = read('ake-datasets/datasets/SemEval-2010/test')\n",
    "len(train_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 3))\n",
    "trainvec = vectorizer.fit_transform(train_sentences.values())\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ake-datasets/datasets/SemEval-2010/references/test.author.stem.json', 'r') as f:\n",
    "    target = json.load(f)\n",
    "    target = {doc_name: [k[0] for k in keyphrases] for doc_name, keyphrases in target.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imag retriev', 'activ learn', 'relev feedback']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['H-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laplacian optimal design for imag e retrieval\n",
      "abstract\n",
      "relevance feedback be a powerful technique to enhance contentbased image retrieval -lrb- cbir -rrb- performance .\n",
      "it solicit the user 's relevance judgment on the retrieve image return by the cbir system .\n",
      "the user 's labeling be then use to learn a classifier to distinguish between relevant and irrelevant image .\n",
      "however , the top return image may not be the most informative one .\n",
      "the challenge be thus to determine which unlabeled image would be the most informative -lrb- i.e. , improve the classifier the most -rrb- if they be label and use as training sample .\n",
      "in this paper , we propose a novel active learning algorithm , call laplacian optimal design -lrb- lod -rrb- , for relevance feedback image retrieval .\n",
      "we algorithm be base on a regression model which minimize the least square error on the measure -lrb- or , label -rrb- image and simultaneously preserve the local geometrical structure of the image space .\n",
      "specifically , we assume that if two image be sufficiently close to each other , then they measurement -lrb- or , label -rrb- be close as well .\n",
      "by construct a nearest neighbor graph , the geometrical structure of the image space can be describe by the graph laplacian .\n",
      "we discuss how result from the field of optimal experimental design may be use to guide we selection of a subset of image , which give we the most amount of information .\n",
      "experimental result on corel database suggest that the propose approach achieve higher precision in relevance feedback image retrieval .\n",
      "1 .\n",
      "introduction\n",
      "in many machine learning and information retrieval task , there be no shortage of unlabeled datum but label be expensive .\n",
      "the challenge be thus to determine which unlabeled sample would be the most informative -lrb- i.e. , improve the classifier the most -rrb- if they be label and use as training sample .\n",
      "this problem be typically call active learning -lsb- 4 -rsb- .\n",
      "here the task be to minimize a overall cost , which depend both on the classifier accuracy and the cost of datum collection .\n",
      "many real world application can be cast into active learning framework .\n",
      "particularly , we consider the problem of relevance feedback drive content-based image retrieval -lrb- cbir -rrb- -lsb- 13 -rsb- .\n",
      "content-based image retrieval have attract substantial interest in the last decade -lsb- 13 -rsb- .\n",
      "it be motivate by the fast growth of digital image database which , in turn , require efficient search scheme .\n",
      "rather than describe a image use text , in these system a image query be describe use one or more example image .\n",
      "the low level visual feature -lrb- color , texture , shape , etc. -rrb- be automatically extract to represent the image .\n",
      "however , the low level feature may not accurately characterize the high level semantic concept .\n",
      "to narrow down the semantic gap , relevance feedback be introduce into cbir -lsb- 12 -rsb- .\n",
      "in many of the current relevance feedback drive cbir system , the user be require to provide his/her relevance judgment on the top image return by the system .\n",
      "the label image be then use to train a classifier to separate image that match the query concept from those that do not .\n",
      "however , in general the top return image may not be the most informative one .\n",
      "in the worst case , all the top image label by the user may be positive and thus the standard classification technique can not be apply due to the lack of negative example .\n",
      "unlike the standard classification problem where the label sample be pregiven , in relevance feedback image retrieval the system can actively select the image to label .\n",
      "thus active learning can be naturally introduce into image retrieval .\n",
      "despite many exist active learning technique , support vector machine -lrb- svm -rrb- active learning -lsb- 14 -rsb- and regression base active learning -lsb- 1 -rsb- have receive the most interest .\n",
      "base on the observation that the closer to the svm boundary a image be , the less reliable its classification be , svm active learning select those unlabeled image closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two class .\n",
      "the major disadvantage of svm active learning be that the estimate boundary may not be accurate enough .\n",
      "moreover , it may not be apply at the beginning of the retrieval when there be no labeled image .\n",
      "some other svm base active learning algorithm can be find in -lsb- 7 -rsb- , -lsb- 9 -rsb- .\n",
      "in statistics , the problem of select sample to label be typically refer to as experimental design .\n",
      "the sample x be refer to as experiment , and its label y be refer to as measurement .\n",
      "the study of optimal experimental design -lrb- oed -rrb- -lsb- 1 -rsb- be concern with the design of experiment that be expect to minimize variance of a parameterized model .\n",
      "the intent of optimal experimental design be usually to maximize confidence in a give model , minimize parameter variance for system identification , or minimize the model 's output variance .\n",
      "classical experimental design approach include a-optimal design , d-optimal design , and e-optimal design .\n",
      "all of these approach be base on a least square regression model .\n",
      "compare to svm base active learning algorithm , experimental design approach be much more efficient in computation .\n",
      "however , this kind of approach take only measure -lrb- or , label -rrb- datum into account in they objective function , while the unmeasured -lrb- or , unlabeled -rrb- datum be ignore .\n",
      "benefit from recent progress on optimal experimental design and semi-supervised learning , in this paper we propose a novel active learning algorithm for image retrieval , call laplacian optimal design -lrb- lod -rrb- .\n",
      "unlike traditional experimental design method whose loss function be only define on the measure point , the loss function of we propose lod algorithm be define on both measure and unmeasured point .\n",
      "specifically , we introduce a locality preserve regularizer into the standard least-square-error base loss function .\n",
      "the new loss function aim to find a classifier which be locally as smooth as possible .\n",
      "in other word , if two point be sufficiently close to each other in the input space , then they be expect to share the same label .\n",
      "once the loss function be define , we can select the most informative datum point which be present to the user for labeling .\n",
      "it would be important to note that the most informative image may not be the top return image .\n",
      "the rest of the paper be organize as follow .\n",
      "in section 2 , we provide a brief description of the related work .\n",
      "we propose laplacian optimal design algorithm be introduce in section 3 .\n",
      "in section 4 , we compare we algorithm with the state-or-the-art algorithm and present the experimental result on image retrieval .\n",
      "finally , we provide some conclude remark and suggestion for future work in section 5 .\n",
      "2 .\n",
      "related work\n",
      "since we propose algorithm be base on regression framework .\n",
      "the most related work be optimal experimental design -lsb- 1 -rsb- , include a-optimal design , d-optimal design , and eoptimal design .\n",
      "in this section , we give a brief description of these approach .\n",
      "2.1 the active learning problem\n",
      "the generic problem of active learning be the follow .\n",
      "give a set of point a = -lcb- x1 , x2 , · · · , xm -rcb- in rd , find a subset b = -lcb- z1 , z2 , · · · , zk -rcb- c a which contain the most informative point .\n",
      "in other word , the point zi -lrb- i = 1 , · · · , k -rrb- can improve the classifier the most if they be label and use as training point .\n",
      "2.2 optimal experimental design\n",
      "we consider a linear regression model\n",
      "where y be the observation , x be the independent variable , w be the weight vector and ~ be a unknown error with zero mean .\n",
      "different observation have error that be independent , but with equal variance σ2 .\n",
      "we define f -lrb- x -rrb- = wt x to be the learner 's output give input x and the weight vector w. suppose we have a set of label sample point -lrb- z1 , y1 -rrb- , · · · , -lrb- zk , yk -rrb- , where yi be the label of zi .\n",
      "thus , the maximum likelihood estimate for the weight vector , ˆw , be that which minimize the sum square error\n",
      "by gauss-markov theorem , we know that wˆ − w have a zero mean and a covariance matrix give by σ2h − 1 sse , where hsse be the hessian of jsse -lrb- w -rrb-\n",
      "where z = -lrb- z1 , z2 , · · · , zk -rrb- .\n",
      "the three most common scalar measure of the size of the parameter covariance matrix in optimal experimental design\n",
      "be : • d-optimal design : determinant of hsse .\n",
      "• a-optimal design : trace of hsse .\n",
      "• e-optimal design : maximum eigenvalue of hsse .\n",
      "since the computation of the determinant and eigenvalue of a matrix be much more expensive than the computation of matrix trace , a-optimal design be more efficient than the other two .\n",
      "some recent work on experimental design can be find in -lsb- 6 -rsb- , -lsb- 16 -rsb- .\n",
      "3 .\n",
      "laplacian optimal design\n",
      "since the covariance matrix hsse use in traditional approach be only dependent on the measure sample , i.e. zi 's , these approach fail to evaluate the expected error on the unmeasured sample .\n",
      "in this section , we introduce a novel active learning algorithm call laplacian optimal design -lrb- lod -rrb- which make efficient use of both measure -lrb- label -rrb- and unmeasured -lrb- unlabeled -rrb- sample .\n",
      "3.1 the objective function\n",
      "in many machine learning problem , it be natural to assume that if two point xi , xj be sufficiently close to each other , then they measurement -lrb- f -lrb- xi -rrb- , f -lrb- xj -rrb- -rrb- be close as\n",
      "well .\n",
      "let s be a similarity matrix .\n",
      "thus , a new loss function which respect the geometrical structure of the datum space can be define as follow : where yi be the measurement -lrb- or , label -rrb- of zi .\n",
      "note that , the loss function -lrb- 3 -rrb- be essentially the same as the one use in laplacian regularized regression -lrb- lrr , -lsb- 2 -rsb- -rrb- .\n",
      "however , lrr be a passive learning algorithm where the training datum be give .\n",
      "in this paper , we be focus on how to select the most informative datum for training .\n",
      "the loss function with we choice of symmetric weight sij -lrb- sij = sji -rrb- incur a heavy penalty if neighbor point xi and xj be map far apart .\n",
      "therefore , minimize j0 -lrb- w -rrb- be a attempt to ensure that if xi and xj be close then f -lrb- xi -rrb- and f -lrb- xj -rrb- be close as well .\n",
      "there be many choice of the similarity matrix s .\n",
      "a simple definition be as follow :\n",
      "let d be a diagonal matrix , dii = ~ j sij , and l = d − s .\n",
      "the matrix l be call graph laplacian in spectral graph theory -lsb- 3 -rsb- .\n",
      "let y = -lrb- y1 , · · · , yk -rrb- t and x = -lrb- x1 , · · · , xm -rrb- .\n",
      "follow some simple algebraic step , we see that :\n",
      "where i be a identity matrix and λ = λ1xlxt + λ2i .\n",
      "clearly , h be of full rank .\n",
      "require that the gradient of j -lrb- w -rrb- with respect to w vanish give the optimal estimate ˆw :\n",
      "the follow proposition state the bias and variance property of the estimator for the coefficient vector w.\n",
      "for any x , let yˆ = ˆwt x be its predict observation .\n",
      "the expect square prediction error be e -lrb- y − ˆy -rrb- 2\n",
      "in some case , the matrix zzt + λxlxt be singular -lrb- e.g. if m < d -rrb- .\n",
      "thus , there be no stable solution to the optimization problem eq .\n",
      "-lrb- 3 -rrb- .\n",
      "a common way to deal with this ill-posed problem be to introduce a tikhonov regularizer into we loss function : j -lrb- w -rrb- clearly the expect square prediction error depend on the explanatory variable x , therefore average expect square predictive error over the complete data set a be\n",
      "we laplacian optimality criterion be thus formulate by minimize the trace of xt h − 1x .\n",
      "where z1 , · · · , zk be select from -lcb- x1 , · · · , xm -rcb- .\n",
      "4 .\n",
      "kernel laplacian optimal design\n",
      "canonical experimental design approach -lrb- e.g. a-optimal design , d-optimal design , and e-optimal -rrb- only consider linear function .\n",
      "they fail to discover the intrinsic geometry in the datum when the datum space be highly nonlinear .\n",
      "in this section , we describe how to perform laplacian experimental design in reproduce kernel hilbert space -lrb- rkh -rrb- which give rise to kernel laplacian experimental design -lrb- klod -rrb- .\n",
      "for give datum point x1 , · · · , xm ∈ x with a positive definite mercer kernel k : x × x → r , there exist a unique rkhs hk of real value function on x. let kt -lrb- s -rrb- be the function of s obtain by fix t and let kt -lrb- s -rrb- .\n",
      "= k -lrb- s , t -rrb- .\n",
      "hk consist of all finite linear combination of the form ~ li = 1 αikti with ti ∈ x and limit of such function as the ti become dense in x .\n",
      "we have ~ k , kt ~ hk = k -lrb- s , t -rrb- .\n",
      "4.1 derivation of lod in reproducing kernel hilbert space\n",
      "consider the optimization problem -lrb- 5 -rrb- in rkhs .\n",
      "thus , we seek a function f ∈ hk such that the follow objective function be minimize :\n",
      "we have the follow proposition .\n",
      "proof .\n",
      "let h ⊥ be the orthogonal complement of h , i.e. hk = h ⊕ h ⊥ .\n",
      "thus , for any function f ∈ hk , it have orthogonal decomposition as follow :\n",
      "notice that kxi ∈ h while fh ⊥ ∈ h ⊥ .\n",
      "this imply that ~ fh ⊥ , kxi ~ hk = 0 .\n",
      "therefore , f -lrb- xi -rrb- = ~ fh , kxi ~ hk = fh -lrb- xi -rrb- this complete the proof .\n",
      "proposition 4.1 tell we the minimizer of problem -lrb- 12 -rrb- admit a representation f ∗ = ~ mi = 1 αik -lrb- · , xi -rrb- .\n",
      "please see -lsb- 2 -rsb- for the detail .\n",
      "let φ : rd → h be a feature map from the input space rd to h , and k -lrb- xi , xj -rrb- = < φ -lrb- xi -rrb- , φ -lrb- xj -rrb- > .\n",
      "let x denote the datum matrix in rkh , x = -lrb- φ -lrb- x1 -rrb- , φ -lrb- x2 -rrb- , · · · , φ -lrb- xm -rrb- -rrb- .\n",
      "similarly , we define z = -lrb- φ -lrb- z1 -rrb- , φ -lrb- z2 -rrb- , · · · , φ -lrb- zk -rrb- -rrb- .\n",
      "thus , the optimization problem in rkhs can be write as follow :\n",
      "since the mapping function φ be generally unknown , there be no direct way to solve problem -lrb- 13 -rrb- .\n",
      "in the follow , we apply kernel trick to solve this optimization problem .\n",
      "let x − 1 be the moore-penrose inverse -lrb- also know as pseudo inverse -rrb- of x. thus , we have :\n",
      "where kxx be a m × m matrix -lrb- kxx , ij = k -lrb- xi , xj -rrb- -rrb- , kxz be a m × k matrix -lrb- kxz , ij = k -lrb- xi , zj -rrb- -rrb- , and kzx be a k × m matrix -lrb- kzx , ij = k -lrb- zi , xj -rrb- -rrb- .\n",
      "thus , the kernel laplacian optimal design can be define as follow :\n",
      "4.2 optimization scheme\n",
      "in this subsection , we discuss how to solve the optimization problem -lrb- 11 -rrb- and -lrb- 14 -rrb- .\n",
      "particularly , if we select a linear kernel for klod , then it reduce to lod .\n",
      "therefore , we will focus on problem -lrb- 14 -rrb- in the follow .\n",
      "it can be show that the optimization problem -lrb- 14 -rrb- be np-hard .\n",
      "in this subsection , we develop a simple sequential greedy approach to solve -lrb- 14 -rrb- .\n",
      "suppose n point have be select , denote by a matrix zn = -lrb- z1 , · · · , zn -rrb- .\n",
      "the -lrb- n + 1 -rrb- - th point zn +1 can be select by solve the follow optimization problem :\n",
      "if the kernel function be choose as inner product k -lrb- x , y -rrb- = -lrb- x , y -rrb- , then wk be a linear functional space and the algorithm reduce to lod .\n",
      "5 .\n",
      "content-based image retrieval using laplacian optimal design\n",
      "in this section , we describe how to apply laplacian optimal design to cbir .\n",
      "we begin with a brief description of image representation use low level visual feature .\n",
      "5.1 low-level image representation\n",
      "low-level image representation be a crucial problem in cbir .\n",
      "general visual feature include color , texture , shape , etc. .\n",
      "color and texture feature be the most extensively use visual feature in cbir .\n",
      "compare with color and texture feature , shape feature be usually describe after image have be segmented into region or object .\n",
      "since robust and accurate image segmentation be difficult to achieve , the use of shape feature for image retrieval have be limit to special application where object or region be readily available .\n",
      "in this work , we combine 64-dimensional color histogram and 64-dimensional color texture moment -lrb- ctm , -lsb- 15 -rsb- -rrb- to represent the image .\n",
      "the color histogram be calculate use 4 x 4 x 4 bin in hsv space .\n",
      "the color texture moment be propose by yu et al. -lsb- 15 -rsb- , which integrate the color and texture characteristic of the image in a compact form .\n",
      "ctm adopt local fourier transform as a texture representation scheme and derive eight characteristic map to describe different aspect of co-occurrence relation of image pixel in each channel of the -lrb- svcosh , svsinh , v -rrb- color space .\n",
      "then ctm calculate the first and second moment of these map as a representation of the natural color image pixel distribution .\n",
      "please see -lsb- 15 -rsb- for detail .\n",
      "5.2 relevance feedback image retrieval\n",
      "relevance feedback be one of the most important technique to narrow down the gap between low level visual feature and high level semantic concept -lsb- 12 -rsb- .\n",
      "traditionally , the user 's relevance feedback be use to update the query vector or adjust the weighting of different dimension .\n",
      "this process can be view as a on-line learning process in which the image retrieval system act as a learner and the user act as a teacher .\n",
      "they typical retrieval process be outline as follow :\n",
      "1 .\n",
      "the user submit a query image example to the system .\n",
      "the system rank the image in database accord to some pre-defined distance metric and present to the user the top rank image .\n",
      "2 .\n",
      "the system select some image from the database and request the user to label they as `` relevant '' or `` irrelevant '' .\n",
      "3 .\n",
      "the system use the user 's provide information to rerank the image in database and return to the user the top image .\n",
      "go to step 2 until the user be satisfied .\n",
      "we laplacian optimal design algorithm be apply in the second step for select the most informative image .\n",
      "once we get the label for the image select by lod , we apply laplacian regularized regression -lrb- lrr , -lsb- 2 -rsb- -rrb- to solve the optimization problem -lrb- 3 -rrb- and build the classifier .\n",
      "the classifier be then use to re-rank the image in database .\n",
      "note that , in order to reduce the computational complexity , we do not use all the unlabeled image in the database but only those within top 500 return of previous iteration .\n",
      "6 .\n",
      "experimental result\n",
      "in this section , we evaluate the performance of we propose algorithm on a large image database .\n",
      "to demonstrate the effectiveness of we propose lod algorithm , we compare it with laplacian regularized regression -lrb- lrr , -lsb- 2 -rsb- -rrb- , support vector machine -lrb- svm -rrb- , support vector machine active learning -lrb- svmactive -rrb- -lsb- 14 -rsb- , and a-optimal design -lrb- aod -rrb- .\n",
      "both svmactive , aod , and lod be active learning algorithm , while lrr and svm be standard classification algorithm .\n",
      "svm only make use of the label image , while lrr be a semi-supervised learning algorithm which make use of both label and unlabeled image .\n",
      "for svmactive , aod , and lod , 10 training image be select by the algorithm themselves at each iteration .\n",
      "while for lrr and svm , we use the top 10 image as training datum .\n",
      "it would be important to note that svmactive be base on the ordinary svm , lod be base on lrr , and aod be base on the ordinary regression .\n",
      "the parameter λ1 and λ2 in we lod algorithm be empirically set to be 0.001 and 0.00001 .\n",
      "for both lrr and lod algorithm , we use the same graph structure -lrb- see eq .\n",
      "4 -rrb- and set the value of p -lrb- number of nearest neighbor -rrb- to be 5 .\n",
      "we begin with a simple synthetic example to give some intuition about how lod work .\n",
      "6.1 simple synthetic example\n",
      "a simple synthetic example be give in figure 1 .\n",
      "the data set contain two circle .\n",
      "eight point be select by aod and lod .\n",
      "as can be see , all the point select by aod be from the big circle , while lod select four point from the big circle and four from the small circle .\n",
      "the number beside the select point denote they order to be select .\n",
      "clearly , the point select by we lod algorithm can better represent the original data set .\n",
      "we do not compare we algorithm with svmactive because svmactive can not be apply in this case due to the lack of the label point .\n",
      "6.2 image retrieval experimental design\n",
      "the image database we use consist of 7,900 image of 79 semantic category , from corel datum set .\n",
      "it be a large and heterogeneous image set .\n",
      "each image be represent as a 128-dimensional vector as describe in section 5.1 .\n",
      "figure 2 show some sample image .\n",
      "to exhibit the advantage of use we algorithm , we need a reliable way of evaluate the retrieval performance and the comparison with other algorithm .\n",
      "we list different aspect of the experimental design below .\n",
      "6.2.1 evaluation metric\n",
      "we use precision-scope curve and precision rate -lsb- 10 -rsb- to evaluate the effectiveness of the image retrieval algorithm .\n",
      "the scope be specify by the number -lrb- n -rrb- of top-ranked image present to the user .\n",
      "the precision be the ratio of the number of relevant image present to the user to the\n",
      "figure 1 : data selection by active learning algorithm .\n",
      "the number beside the select point denote they order to be select .\n",
      "clearly , the point select by we lod algorithm can better represent the original data set .\n",
      "note that , the svmactive algorithm can not be apply in this case due to the lack of label point .\n",
      "figure 2 : sample image from category bead , elephant , and ship .\n",
      "scope n .\n",
      "the precision-scope curve describe the precision with various scope and thus give a overall performance evaluation of the algorithm .\n",
      "on the other hand , the precision rate emphasize the precision at a particular value of scope .\n",
      "in general , it be appropriate to present 20 image on a screen .\n",
      "put more image on a screen may affect the quality of the present image .\n",
      "therefore , the precision at top 20 -lrb- n = 20 -rrb- be especially important .\n",
      "in real world image retrieval system , the query image be usually not in the image database .\n",
      "to simulate such environment , we use five-fold cross validation to evaluate the algorithm .\n",
      "more precisely , we divide the whole image database into five subset with equal size .\n",
      "thus , there be 20 image per category in each subset .\n",
      "at each run of cross validation , one subset be select as the query set , and the other four subset be use as the database for retrieval .\n",
      "the precisionscope curve and precision rate be compute by average the result from the five-fold cross validation .\n",
      "6.2.2 automatic relevance feedback scheme\n",
      "we design a automatic feedback scheme to model the retrieval process .\n",
      "for each submit query , we system retrieve and rank the image in the database .\n",
      "10 image be select from the database for user labeling and the label information be use by the system for re-ranking .\n",
      "note that , the image which have be select at previous iteration be exclude from later selection .\n",
      "for each query , the automatic relevance feedback mechanism be perform for four iteration .\n",
      "it be important to note that the automatic relevance feedback scheme use here be different from the one describe in -lsb- 8 -rsb- , -lsb- 11 -rsb- .\n",
      "in -lsb- 8 -rsb- , -lsb- 11 -rsb- , the top four relevant and irrelevant image be select as the feedback image .\n",
      "however , this may not be practical .\n",
      "in real world image retrieval system , it be possible that most of the top-ranked image be relevant -lrb- or , irrelevant -rrb- .\n",
      "thus , it be difficult for the user to find both four relevant and irrelevant image .\n",
      "it be more reasonable for the user to provide feedback information only on the 10 image select by the system .\n",
      "6.3 image retrieval performance\n",
      "in real world , it be not practical to require the user to provide many round of feedback .\n",
      "the retrieval performance after the first two round of feedback -lrb- especially the first round -rrb- be more important .\n",
      "figure 3 show the average precision-scope curve of the different algorithm for the first two feedback iteration .\n",
      "at the beginning of retrieval , the euclidean distance in the original 128-dimensional space be use to rank the image in database .\n",
      "after the user provide relevance feedback , the lrr , svm , svmactive , aod , and lod algorithm be then apply to re-rank the image .\n",
      "in order to reduce the time complexity of active learning algorithm , we do not select the most informative image from the whole database but from the top 500 image .\n",
      "for lrr and svm , the user be require to label the top 10 image .\n",
      "for svmactive , aod , and lod , the user be require to label 10 most informative image select by these algorithm .\n",
      "note that , svmactive can only be ap\n",
      "figure 3 : the average precision-scope curve of different algorithm for the first two feedback iteration .\n",
      "the lod algorithm perform the best on the entire scope .\n",
      "note that , at the first round of feedback , the svmactive algorithm can not be apply .\n",
      "it apply the ordinary svm to build the initial classifier .\n",
      "figure 4 : performance evaluation of the five learning algorithm for relevance feedback image retrieval .\n",
      "-lrb- a -rrb- precision at top 10 , -lrb- b -rrb- precision at top 20 , and -lrb- c -rrb- precision at top 30 .\n",
      "as can be see , we lod algorithm consistently outperform the other four algorithm .\n",
      "ply when the classifier be already build .\n",
      "therefore , it can not be apply at the first round and we use the standard svm to build the initial classifier .\n",
      "as can be see , we lod algorithm outperform the other four algorithm on the entire scope .\n",
      "also , the lrr algorithm perform better than svm .\n",
      "this be because that the lrr algorithm make efficient use of the unlabeled image by incorporate a locality preserve regularizer into the ordinary regression objective function .\n",
      "the aod algorithm perform the worst .\n",
      "as the scope get larger , the performance difference between these algorithm get smaller .\n",
      "by iteratively add the user 's feedback , the corresponding precision result -lrb- at top 10 , top 20 , and top 30 -rrb- of the five algorithm be respectively show in figure 4 .\n",
      "as can be see , we lod algorithm perform the best in all the case and the lrr algorithm perform the second best .\n",
      "both of these two algorithm make use of the unlabeled image .\n",
      "this show that the unlabeled image be helpful for discover the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance .\n",
      "in real world , the user may not be willing to provide too many relevance feedback .\n",
      "therefore , the retrieval performance at the first two round be especially important .\n",
      "as can be see , we lod algorithm achieve 6.8 % performance improvement for top 10 result , 5.2 % for top 20 result , and 4.1 % for top 30 result , compare to the second best algorithm -lrb- lrr -rrb- after the first two round of relevance feedback .\n",
      "6.4 discussion\n",
      "several experiment on corel database have be systematically perform .\n",
      "we would like to highlight several interesting point : 1 .\n",
      "it be clear that the use of active learning be beneficial in the image retrieval domain .\n",
      "there be a significant increase in performance from use the active learning method .\n",
      "especially , out of the three active learn method -lrb- svmactive , aod , lod -rrb- , we propose lod algorithm perform the best .\n",
      "2 .\n",
      "in many real world application like relevance feedback image retrieval , there be generally two way of reduce labor-intensive manual labeling task .\n",
      "one be active learning which select the most informative sample to label , and the other be semi-supervised learning which make use of the unlabeled sample to enhance the learning performance .\n",
      "both of these two strategy have be study extensively in the past -lsb- 14 -rsb- ,\n",
      "-lsb- 7 -rsb- , -lsb- 5 -rsb- , -lsb- 8 -rsb- .\n",
      "the work present in this paper be focus on active learning , but it also take advantage of the recent progress on semi-supervised learning -lsb- 2 -rsb- .\n",
      "specifically , we incorporate a locality preserve regularizer into the standard regression framework and find the most informative sample with respect to the new objective function .\n",
      "in this way , the active learning and semi-supervised learning technique be seamlessly unify for learn a optimal classifier .\n",
      "3 .\n",
      "the relevance feedback technique be crucial to image retrieval .\n",
      "for all the five algorithm , the retrieval performance improve with more feedback provide by the user .\n",
      "7 .\n",
      "conclusion and future work\n",
      "this paper describe a novel active learning algorithm , call laplacian optimal design , to enable more effective relevance feedback image retrieval .\n",
      "we algorithm be base on a objective function which simultaneously minimize the empirical error and preserve the local geometrical structure of the datum space .\n",
      "use technique from experimental design , we algorithm find the most informative image to label .\n",
      "these label image and the unlabeled image in the database be use to learn a classifier .\n",
      "the experimental result on corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance .\n",
      "in this paper , we consider the image retrieval problem on a small , static , and closed-domain image datum .\n",
      "a much more challenging domain be the world wide web -lrb- www -rrb- .\n",
      "for web image search , it be possible to collect a large amount of user click information .\n",
      "this information can be naturally use to construct the affinity graph in we algorithm .\n",
      "however , the computational complexity in web scenario may become a crucial issue .\n",
      "also , although we primary interest in this paper be focus on relevance feedback image retrieval , we result may also be of interest to researcher in patten recognition and machine learning , especially when a large amount of datum be available but only a limited sample can be label .\n"
     ]
    }
   ],
   "source": [
    "print(test_sentences['H-11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyphrases(vec, feature_names, nb_keywords=5):\n",
    "    feature_index = vec.nonzero()[1]\n",
    "    tfidf_scores = zip(feature_index, [vec[0, x] for x in feature_index])\n",
    "    # Scale scores by n-gram length\n",
    "    scores = {feature_names[i]: s * len(feature_names[i].split()) for i, s in tfidf_scores}\n",
    "    scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[:nb_keywords]\n",
    "    return [keyphrase for keyphrase, score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for doc_id, doc in test_sentences.items():\n",
    "    vec = vectorizer.transform([doc])[0]\n",
    "    keyphrases = extract_keyphrases(vec, feature_names=feature_names, nb_keywords=5)\n",
    "    predictions[doc_id] = keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['image',\n",
       "  'image retrieval',\n",
       "  'active learning',\n",
       "  'experimental design',\n",
       "  'image database'],\n",
       " ['imag retriev', 'activ learn', 'relev feedback'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['H-11'], target['H-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {doc_id: [sno.stem(candidate) for candidate in candidates] for doc_id, candidates in predictions.items()}\n",
    "target = {doc_id: [sno.stem(candidate) for candidate in candidates] for doc_id, candidates in target.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-1   -> Precision: 0.20 Recall: 0.17 F1: 0.18 precision@5: 0.20\n",
      "C-14  -> Precision: 0.40 Recall: 0.40 F1: 0.40 precision@5: 0.40\n",
      "C-17  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-18  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-19  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "C-20  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "C-22  -> Precision: 0.20 Recall: 0.25 F1: 0.22 precision@5: 0.20\n",
      "C-23  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-27  -> Precision: 0.20 Recall: 0.25 F1: 0.22 precision@5: 0.20\n",
      "C-28  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-29  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-3   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-30  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "C-31  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-32  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-33  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "C-34  -> Precision: 0.20 Recall: 0.20 F1: 0.20 precision@5: 0.20\n",
      "C-36  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-38  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-4   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-40  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-6   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-8   -> Precision: 0.20 Recall: 0.14 F1: 0.17 precision@5: 0.20\n",
      "C-86  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "C-9   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-10  -> Precision: 0.25 Recall: 0.50 F1: 0.33 precision@5: 0.25\n",
      "H-11  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-12  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-13  -> Precision: 0.20 Recall: 0.25 F1: 0.22 precision@5: 0.20\n",
      "H-14  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-16  -> Precision: 0.25 Recall: 0.25 F1: 0.25 precision@5: 0.25\n",
      "H-17  -> Precision: 0.20 Recall: 0.25 F1: 0.22 precision@5: 0.20\n",
      "H-18  -> Precision: 0.25 Recall: 0.17 F1: 0.20 precision@5: 0.00\n",
      "H-19  -> Precision: 0.20 Recall: 0.25 F1: 0.22 precision@5: 0.20\n",
      "H-2   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-20  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-21  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-24  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-25  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-26  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-29  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-3   -> Precision: 0.20 Recall: 0.25 F1: 0.22 precision@5: 0.20\n",
      "H-30  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-31  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-32  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-4   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-5   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-7   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-8   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "H-9   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-1   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-10  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-11  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-12  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-14  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-15  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-16  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "I-18  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-19  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-20  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-21  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-22  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-26  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-29  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-30  -> Precision: 0.60 Recall: 0.60 F1: 0.60 precision@5: 0.60\n",
      "I-31  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-32  -> Precision: 0.25 Recall: 0.33 F1: 0.29 precision@5: 0.25\n",
      "I-33  -> Precision: 0.20 Recall: 0.25 F1: 0.22 precision@5: 0.20\n",
      "I-34  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-35  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-4   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-5   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-6   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "I-7   -> Precision: 0.20 Recall: 0.25 F1: 0.22 precision@5: 0.20\n",
      "I-9   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-1   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-10  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-11  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-13  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "J-14  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "J-15  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "J-17  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-18  -> Precision: 0.40 Recall: 0.67 F1: 0.50 precision@5: 0.40\n",
      "J-2   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-20  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-21  -> Precision: 0.20 Recall: 0.17 F1: 0.18 precision@5: 0.20\n",
      "J-22  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-23  -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "J-25  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-26  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-27  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-28  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-3   -> Precision: 0.20 Recall: 0.25 F1: 0.22 precision@5: 0.20\n",
      "J-30  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-31  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-32  -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-4   -> Precision: 0.20 Recall: 0.33 F1: 0.25 precision@5: 0.20\n",
      "J-7   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-8   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "J-9   -> Precision: 0.00 Recall: 0.00 F1: 0.00 precision@5: 0.00\n",
      "\n",
      "--------------Mean-------------\n",
      "Precision: 0.07 Recall: 0.09 F1: 0.08   precision@5: 0.07\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, precision_5 = [], [], [], []\n",
    "for doc_id in sorted(predictions.keys()):\n",
    "    p = set(predictions[doc_id])\n",
    "    t = set(target[doc_id])\n",
    "    at_5 = set(target[doc_id][:5])\n",
    "\n",
    "    # We always predict 5 keywords\n",
    "    precision.append(len(p.intersection(t)) / len(p))\n",
    "    recall.append(len(p.intersection(t)) / len(t))\n",
    "    f1.append(0 if precision[-1] + recall[-1] == 0 else 2 * precision[-1] * recall[-1] / (precision[-1] + recall[-1]))\n",
    "    precision_5.append(len(p.intersection(at_5)) / len(p))\n",
    "    print(f'{doc_id:5} -> Precision: {precision[-1]:.2f} Recall: {recall[-1]:.2f} F1: {f1[-1]:.2f} precision@5: {precision_5[-1]:.2f}')\n",
    "\n",
    "print()\n",
    "print('--------------Mean-------------')\n",
    "print(f'Precision: {np.mean(precision):.2f} Recall: {np.mean(recall):.2f} F1: {np.mean(f1):.2f}   precision@5: {np.mean(precision_5):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
