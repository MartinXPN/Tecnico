{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.metrics.distance import jaccard_distance, edit_distance\n",
    "from nltk.stem import SnowballStemmer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "import spacy\n",
    "from spacy.lang.pt.examples import sentences \n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "doc = ET.parse('Project1/KB.xml')\n",
    "sno = SnowballStemmer('portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the dataset\n",
    "* As there are some questions that repeat and those map to different answers at the same time, we decided to keep only the first question -> answer mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "reference: Dict[str, Tuple[int, str]] = {}\n",
    "\n",
    "for document in doc.findall('documento'):\n",
    "    for faq in document.find('faq_list').findall('faq'):\n",
    "        answer = faq.find('resposta')\n",
    "        idx = answer.attrib['id']\n",
    "        answer = answer.text.strip()\n",
    "        \n",
    "        for question in faq.find('perguntas').findall('pergunta'):\n",
    "            question = question.text.strip()\n",
    "            if question == '' or question in reference:\n",
    "                continue\n",
    "            data.append((question, answer, idx))\n",
    "            reference[question] = (idx, answer)\n",
    "\n",
    "data = pd.DataFrame(data, columns=['question', 'answer', 'answer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = []\n",
    "annotated = []\n",
    "filter_annotated = []\n",
    "tokenized_questions = []\n",
    "lemma_filtered = []\n",
    "stem_filtered = []\n",
    "stem = []\n",
    "\n",
    "for i, row in tqdm(data.iterrows()):\n",
    "    doc = nlp(row['question'])\n",
    "    tokenized_questions.append(' '.join([token.text.lower() for token in doc]))\n",
    "    annotated.append(' '.join([token.text.lower() + ' ' + token.pos_ for token in doc]))\n",
    "    filtered.append(' '.join([token.text.lower() for token in doc if token.is_alpha and not token.is_stop]))\n",
    "    filter_annotated.append(' '.join([token.text.lower() + ' ' + token.pos_ for token in doc if token.is_alpha and not token.is_stop]))\n",
    "    lemma_filtered.append(' '.join([token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]))\n",
    "    stem_filtered.append(' '.join([sno.stem(token.text.lower()) for token in doc if token.is_alpha and not token.is_stop]))\n",
    "    stem.append(' '.join([sno.stem(token.text.lower()) for token in doc]))\n",
    "\n",
    "data['question'] = tokenized_questions\n",
    "data['filtered'] = filtered\n",
    "data['annotated'] = annotated\n",
    "data['filter_annotated'] = filter_annotated\n",
    "data['lemma_filtered'] = filter_annotated\n",
    "data['stem_filtered'] = stem_filtered\n",
    "data['stem'] = stem\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.3)\n",
    "train.sort_index(inplace=True)\n",
    "test.sort_index(inplace=True)\n",
    "print(f'{len(data)} -> {len(train)}, {len(test)}')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make answers that don't show up in the train data appear as `answer_id = 0` in test\n",
    "available_answer_ids = list(set(train['answer_id'].values))\n",
    "for i, row in test.iterrows():\n",
    "    if row['answer_id'] not in available_answer_ids:\n",
    "        test.at[i, 'answer_id'] = 0\n",
    "        print('No available id for row:', i)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "* Word-level distance measures: nltk.metrics.distance.*\n",
    "* scale distance by the length of the sentence (ok to have few differences in long sentences)\n",
    "* Annotate the initial sentence with spaCy (POS tags, etc)\n",
    "* remove stopwords, punctuation, and everything that is not alphabetical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(q, corpus, distance, threshold=10, column='question'):\n",
    "    \"\"\"Return answer_id with the most similar question\"\"\"\n",
    "    distances = [distance(q, row[column]) for i, row in corpus.iterrows()]\n",
    "    best_match = np.argmin([distances])\n",
    "    \n",
    "    if distances[best_match] >= threshold:\n",
    "        return 0, distances[best_match]\n",
    "    return corpus.iloc[best_match]['answer_id'], distances[best_match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "def tfidf(a, b):\n",
    "    if a not in cache: cache[a] = vectorizer.transform([a])\n",
    "    if b not in cache: cache[b] = vectorizer.transform([b])\n",
    "    avec = cache[a]\n",
    "    bvec = cache[b]\n",
    "    cosine_similarities = linear_kernel(avec, bvec).flatten()\n",
    "    return 1 - cosine_similarities[0]\n",
    "\n",
    "\n",
    "distance_thresholds = [\n",
    "    ('tf-idf', tfidf, 0.6),\n",
    "    ('tf-idf', tfidf, 0.7),\n",
    "    ('tf-idf', tfidf, 0.8),\n",
    "    ('jaccard', lambda a, b: jaccard_distance(set(a.split()), set(b.split())), 0.6),\n",
    "    ('jaccard', lambda a, b: jaccard_distance(set(a.split()), set(b.split())), 0.7),\n",
    "    ('jaccard', lambda a, b: jaccard_distance(set(a.split()), set(b.split())), 0.8),\n",
    "    ('edit_distance', lambda a, b: edit_distance(a.split(), b.split()), 8),\n",
    "    ('edit_distance', lambda a, b: edit_distance(a.split(), b.split()), 16),\n",
    "    ('edit_distance', lambda a, b: edit_distance(a.split(), b.split()), 24),\n",
    "]\n",
    "columns = [\n",
    "    'question',\n",
    "    'filtered',\n",
    "    'annotated',\n",
    "    'filter_annotated',\n",
    "    'lemma_filtered',\n",
    "    'stem_filtered',\n",
    "    'stem',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(column, distance, threshold, verbose=True):\n",
    "    pred, label, distances = [], [], []\n",
    "    for i, row in tqdm(test.iterrows(), total=len(test), disable=not verbose):\n",
    "        ans_id, dist = query(\n",
    "            row[column],\n",
    "            corpus=train,\n",
    "            distance=distance,\n",
    "            threshold=threshold,\n",
    "            column=column,\n",
    "        )\n",
    "        pred.append(int(ans_id))\n",
    "        distances.append(dist)\n",
    "        label.append(int(row['answer_id']))\n",
    "\n",
    "    acc = accuracy_score(label, pred) * 100\n",
    "    print(f'ACC: {acc:.2f}')\n",
    "    return pred, label, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in columns[::-1]:\n",
    "    cache = {}\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    trainvec = vectorizer.fit_transform(train[c].values)\n",
    "    \n",
    "    for distance_name, distance_measure, threshold in distance_thresholds:\n",
    "        print(f'Evaluating dist: {distance_name}, threshold: {threshold}, column: {c}', end='...')\n",
    "        pred, label, distances = evaluate(column=c, distance=distance_measure, threshold=threshold, verbose=True)\n",
    "#         for p, l, d  in zip(pred, label, distances):\n",
    "#             print(f'pred: {p}, label: {l}, dist: {d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating dist: tf-idf, threshold: 0.6, column: question...ACC: 79.69\n",
    "# Evaluating dist: tf-idf, threshold: 0.7, column: question...ACC: 79.83\n",
    "# Evaluating dist: tf-idf, threshold: 0.8, column: question...ACC: 79.69\n",
    "# Evaluating dist: jaccard, threshold: 0.6, column: question...ACC: 69.10\n",
    "# Evaluating dist: jaccard, threshold: 0.7, column: question...ACC: 71.24\n",
    "# Evaluating dist: jaccard, threshold: 0.8, column: question...ACC: 71.39\n",
    "# Evaluating dist: edit_distance, threshold: 8, column: question...ACC: 49.50\n",
    "# Evaluating dist: edit_distance, threshold: 16, column: question...ACC: 56.22\n",
    "# Evaluating dist: edit_distance, threshold: 24, column: question...ACC: 57.08\n",
    "# Evaluating dist: tf-idf, threshold: 0.6, column: filtered...ACC: 76.54\n",
    "# Evaluating dist: tf-idf, threshold: 0.7, column: filtered...ACC: 76.68\n",
    "# Evaluating dist: tf-idf, threshold: 0.8, column: filtered...ACC: 76.54\n",
    "# Evaluating dist: jaccard, threshold: 0.6, column: filtered...ACC: 72.82\n",
    "# Evaluating dist: jaccard, threshold: 0.7, column: filtered...ACC: 74.68\n",
    "# Evaluating dist: jaccard, threshold: 0.8, column: filtered...ACC: 75.25\n",
    "# Evaluating dist: edit_distance, threshold: 8, column: filtered...ACC: 59.37\n",
    "# Evaluating dist: edit_distance, threshold: 16, column: filtered...ACC: 60.94\n",
    "# Evaluating dist: edit_distance, threshold: 24, column: filtered...ACC: 61.09\n",
    "# Evaluating dist: tf-idf, threshold: 0.6, column: annotated...ACC: 79.40\n",
    "# Evaluating dist: tf-idf, threshold: 0.7, column: annotated...ACC: 79.26\n",
    "# Evaluating dist: tf-idf, threshold: 0.8, column: annotated...ACC: 79.26\n",
    "# Evaluating dist: jaccard, threshold: 0.6, column: annotated...ACC: 68.10\n",
    "# Evaluating dist: jaccard, threshold: 0.7, column: annotated...ACC: 68.10\n",
    "# Evaluating dist: jaccard, threshold: 0.8, column: annotated...ACC: 68.10\n",
    "# Evaluating dist: edit_distance, threshold: 8, column: annotated...ACC: 33.05\n",
    "# Evaluating dist: edit_distance, threshold: 16, column: annotated...ACC: 46.78\n",
    "# Evaluating dist: edit_distance, threshold: 24, column: annotated...ACC: 49.79\n",
    "# Evaluating dist: tf-idf, threshold: 0.6, column: filter_annotated...ACC: 76.39\n",
    "# Evaluating dist: tf-idf, threshold: 0.7, column: filter_annotated...ACC: 76.25\n",
    "# Evaluating dist: tf-idf, threshold: 0.8, column: filter_annotated...ACC: 76.25\n",
    "# Evaluating dist: jaccard, threshold: 0.6, column: filter_annotated...ACC: 70.24\n",
    "# Evaluating dist: jaccard, threshold: 0.7, column: filter_annotated...ACC: 69.67\n",
    "# Evaluating dist: jaccard, threshold: 0.8, column: filter_annotated...ACC: 69.67\n",
    "# Evaluating dist: edit_distance, threshold: 8, column: filter_annotated...ACC: 49.21\n",
    "# Evaluating dist: edit_distance, threshold: 16, column: filter_annotated...ACC: 53.51\n",
    "# Evaluating dist: edit_distance, threshold: 24, column: filter_annotated...ACC: 54.22\n",
    "# Evaluating dist: tf-idf, threshold: 0.6, column: lemma_filtered...ACC: 76.39\n",
    "# Evaluating dist: tf-idf, threshold: 0.7, column: lemma_filtered...ACC: 76.25\n",
    "# Evaluating dist: tf-idf, threshold: 0.8, column: lemma_filtered...ACC: 76.25\n",
    "# Evaluating dist: jaccard, threshold: 0.6, column: lemma_filtered...ACC: 70.24\n",
    "# Evaluating dist: jaccard, threshold: 0.7, column: lemma_filtered...ACC: 69.67\n",
    "# Evaluating dist: jaccard, threshold: 0.8, column: lemma_filtered...ACC: 69.67\n",
    "# Evaluating dist: edit_distance, threshold: 8, column: lemma_filtered...ACC: 49.21\n",
    "# Evaluating dist: edit_distance, threshold: 16, column: lemma_filtered...ACC: 53.51\n",
    "# Evaluating dist: edit_distance, threshold: 24, column: lemma_filtered...ACC: 54.22\n",
    "# Evaluating dist: tf-idf, threshold: 0.6, column: stem_filtered...ACC: 78.40\n",
    "# Evaluating dist: tf-idf, threshold: 0.7, column: stem_filtered...ACC: 78.40\n",
    "# Evaluating dist: tf-idf, threshold: 0.8, column: stem_filtered...ACC: 78.40\n",
    "# Evaluating dist: jaccard, threshold: 0.6, column: stem_filtered...ACC: 75.82\n",
    "# Evaluating dist: jaccard, threshold: 0.7, column: stem_filtered...ACC: 76.82\n",
    "# Evaluating dist: jaccard, threshold: 0.8, column: stem_filtered...ACC: 76.68\n",
    "# Evaluating dist: edit_distance, threshold: 8, column: stem_filtered...ACC: 61.23\n",
    "# Evaluating dist: edit_distance, threshold: 16, column: stem_filtered...ACC: 62.66\n",
    "# Evaluating dist: edit_distance, threshold: 24, column: stem_filtered...ACC: 62.80\n",
    "# Evaluating dist: tf-idf, threshold: 0.6, column: stem...ACC: 83.83\n",
    "# Evaluating dist: tf-idf, threshold: 0.7, column: stem...ACC: 83.69\n",
    "# Evaluating dist: tf-idf, threshold: 0.8, column: stem...ACC: 83.69\n",
    "# Evaluating dist: jaccard, threshold: 0.6, column: stem...ACC: 70.10\n",
    "# Evaluating dist: jaccard, threshold: 0.7, column: stem...ACC: 71.53\n",
    "# Evaluating dist: jaccard, threshold: 0.8, column: stem...ACC: 71.24\n",
    "# Evaluating dist: edit_distance, threshold: 8, column: stem...ACC: 48.64\n",
    "# Evaluating dist: edit_distance, threshold: 16, column: stem...ACC: 54.79\n",
    "# Evaluating dist: edit_distance, threshold: 24, column: stem...ACC: 55.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
