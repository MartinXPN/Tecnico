{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = \"\"\"\n",
    "Jared, Drew, Albert, Kyoko, Archie, Paula, Dame Penelope, Jean Lovegood III, Kyle, Rita, Lois, Lois, Rita, Marion, Raylan, Pavel, Kathy, Stelu, Scarlet, Nicole, Marie\n",
    "\"\"\".strip().split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Jared'],\n",
       " ['Drew'],\n",
       " ['Albert'],\n",
       " ['Kyoko'],\n",
       " ['Archie'],\n",
       " ['Paula'],\n",
       " ['Dame', 'Penelope'],\n",
       " ['Jean', 'Lovegood', 'III'],\n",
       " ['Kyle'],\n",
       " ['Rita'],\n",
       " ['Lois'],\n",
       " ['Lois'],\n",
       " ['Rita'],\n",
       " ['Marion'],\n",
       " ['Raylan'],\n",
       " ['Pavel'],\n",
       " ['Kathy'],\n",
       " ['Stelu'],\n",
       " ['Scarlet'],\n",
       " ['Nicole'],\n",
       " ['Marie']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [name.split() for name in ref]\n",
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerx = 'Lisboa, Jared, Drew, Kyoko, Dame, Jean, Marion, Pavel, Que, Kathy, Argentina, Marie'.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lisboa : False\n",
      "Jared : True\n",
      "Drew : True\n",
      "Kyoko : True\n",
      "Dame : True\n",
      "Jean : True\n",
      "Marion : True\n",
      "Pavel : True\n",
      "Que : False\n",
      "Kathy : True\n",
      "Argentina : False\n",
      "Marie : True\n"
     ]
    }
   ],
   "source": [
    "for found in nerx:\n",
    "    print(found, ':', any(found in ref_name for ref_name in ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 9\n",
      "TN: 0\n",
      "FP: 3\n",
      "FN: 14\n"
     ]
    }
   ],
   "source": [
    "tp = sum(any(found in ref_name for ref_name in ref) for found in nerx)\n",
    "tn = 0\n",
    "fp = sum(not any(found in ref_name for ref_name in ref) for found in nerx)\n",
    "fn = sum(' '.join(present) not in nerx for present in ref)\n",
    "print('TP:', tp)\n",
    "print('TN:', tn)\n",
    "print('FP:', fp)\n",
    "print('FN:', fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.75\n",
      "Recall: 0.391304347826087\n"
     ]
    }
   ],
   "source": [
    "print('Precision:', tp / (tp + fp))\n",
    "print('Recall:', tp / (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'pt_core_news_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3ae1fc3d639e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pt_core_news_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'pt_core_news_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:198: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nada\n",
      "nada\n",
      "Sentence to evaluate:  ond nasc\n",
      "Suggested Tag:  LOCAL\n",
      "Correct Tag:  LOCAL_NASC\n",
      "Closest sentence:  ond vem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  tard qu ir ver jog futebol\n",
      "Suggested Tag:  CONVITE\n",
      "Correct Tag:  CONVITE\n",
      "Closest sentence:  qu ir com gel \n",
      "\n",
      "\n",
      "Sentence to evaluate:  famil\n",
      "Suggested Tag:  ANIV\n",
      "Correct Tag:  FAMILIA\n",
      "Closest sentence:  nasc \n",
      "\n",
      "\n",
      "Sentence to evaluate:  mor aond\n",
      "Suggested Tag:  MORADA\n",
      "Correct Tag:  MORADA\n",
      "Closest sentence:  mor lisbo \n",
      "\n",
      "\n",
      "Sentence to evaluate:  es estud trabalh\n",
      "Suggested Tag:  JOB\n",
      "Correct Tag:  JOB\n",
      "Closest sentence:  estud trabalh \n",
      "\n",
      "\n",
      "Sentence to evaluate:  nao ach pouc estranh\n",
      "Suggested Tag:  SMALL_TALK\n",
      "Correct Tag:  SMALL_TALK\n",
      "Closest sentence:  sab cozinh bem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  quant ano tem\n",
      "Suggested Tag:  IDADE\n",
      "Correct Tag:  IDADE\n",
      "Closest sentence:  quant ano tem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  gener music gost\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  GOSTOS\n",
      "Closest sentence:  music gost \n",
      "\n",
      "\n",
      "Sentence to evaluate:  pod ajudar-m\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  SMALL_TALK\n",
      "Closest sentence:  gost cinem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  costum sair noit\n",
      "Suggested Tag:  HABITOS\n",
      "Correct Tag:  HABITOS\n",
      "Closest sentence:  costum pass aqu \n",
      "\n",
      "\n",
      "Sentence to evaluate:  gost estud\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  GOSTOS\n",
      "Closest sentence:  gost cinem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  tem irma irm\n",
      "Suggested Tag:  FAMILIA\n",
      "Correct Tag:  FAMILIA\n",
      "Closest sentence:  tem irma \n",
      "\n",
      "\n",
      "Sentence to evaluate:  dia hoj\n",
      "Suggested Tag:  ANIV\n",
      "Correct Tag:  SMALL_TALK\n",
      "Closest sentence:  dia aniversari \n",
      "\n",
      "\n",
      "Sentence to evaluate:  gost lasanh\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  GOSTOS\n",
      "Closest sentence:  gost cinem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  numer telefon\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  CONTACTO\n",
      "Closest sentence:  gost cinem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  gost\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  GOSTOS\n",
      "Closest sentence:  gost cinem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  es alun tecn\n",
      "Suggested Tag:  NOME\n",
      "Correct Tag:  JOB\n",
      "Closest sentence:  es filip \n",
      "\n",
      "\n",
      "Sentence to evaluate:  for sair avisas-m\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  SMALL_TALK\n",
      "Closest sentence:  gost sair \n",
      "\n",
      "\n",
      "Sentence to evaluate:  es estud\n",
      "Suggested Tag:  JOB\n",
      "Correct Tag:  JOB\n",
      "Closest sentence:  estud \n",
      "\n",
      "\n",
      "Sentence to evaluate:  estud\n",
      "Suggested Tag:  JOB\n",
      "Correct Tag:  JOB\n",
      "Closest sentence:  estud \n",
      "\n",
      "\n",
      "Sentence to evaluate:  ond vem\n",
      "Suggested Tag:  LOCAL\n",
      "Correct Tag:  LOCAL\n",
      "Closest sentence:  ond vem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  ond encontr\n",
      "Suggested Tag:  LOCAL\n",
      "Correct Tag:  SMALL_TALK\n",
      "Closest sentence:  ond vem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  gost faz temp livr\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  HABITOS\n",
      "Closest sentence:  gost faz temp livr \n",
      "\n",
      "\n",
      "Sentence to evaluate:  tem idad\n",
      "Suggested Tag:  FAMILIA\n",
      "Correct Tag:  IDADE\n",
      "Closest sentence:  tem filh \n",
      "\n",
      "\n",
      "Sentence to evaluate:  ond estud\n",
      "Suggested Tag:  JOB\n",
      "Correct Tag:  JOB\n",
      "Closest sentence:  ond estud \n",
      "\n",
      "\n",
      "Sentence to evaluate:  gost ler ver film\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  GOSTOS\n",
      "Closest sentence:  gost ler \n",
      "\n",
      "\n",
      "Sentence to evaluate:  tem algum irma irm\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  FAMILIA\n",
      "Closest sentence:  tem algum hobby \n",
      "\n",
      "\n",
      "Sentence to evaluate:  es ond\n",
      "Suggested Tag:  LOCAL_NASC\n",
      "Correct Tag:  LOCAL\n",
      "Closest sentence:  nasc ond \n",
      "\n",
      "\n",
      "Sentence to evaluate:  and escol\n",
      "Suggested Tag:  JOB\n",
      "Correct Tag:  JOB\n",
      "Closest sentence:  and faculdad \n",
      "\n",
      "\n",
      "Sentence to evaluate:  cor prefer\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  GOSTOS\n",
      "Closest sentence:  passatemp prefer \n",
      "\n",
      "\n",
      "Sentence to evaluate:  corr dia\n",
      "Suggested Tag:  SMALL_TALK\n",
      "Correct Tag:  SMALL_TALK\n",
      "Closest sentence:  vai dia \n",
      "\n",
      "\n",
      "Sentence to evaluate:  faz\n",
      "Suggested Tag:  SMALL_TALK\n",
      "Correct Tag:  HABITOS\n",
      "Closest sentence:  faz \n",
      "\n",
      "\n",
      "Sentence to evaluate:  faz vid\n",
      "Suggested Tag:  SMALL_TALK\n",
      "Correct Tag:  JOB\n",
      "Closest sentence:  faz \n",
      "\n",
      "\n",
      "Sentence to evaluate:  idad tem\n",
      "Suggested Tag:  JOB\n",
      "Correct Tag:  IDADE\n",
      "Closest sentence:  disciplin tem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  gost ler\n",
      "Suggested Tag:  GOSTOS\n",
      "Correct Tag:  GOSTOS\n",
      "Closest sentence:  gost ler \n",
      "\n",
      "\n",
      "Sentence to evaluate:  bem\n",
      "Suggested Tag:  SAUDACAO\n",
      "Correct Tag:  SAUDACAO\n",
      "Closest sentence:  tud bem \n",
      "\n",
      "\n",
      "Sentence to evaluate:  trabalh\n",
      "Suggested Tag:  JOB\n",
      "Correct Tag:  JOB\n",
      "Closest sentence:  trabalh \n",
      "\n",
      "\n",
      "Sentence to evaluate:  es cas\n",
      "Suggested Tag:  NOME\n",
      "Correct Tag:  FAMILIA\n",
      "Closest sentence:  es filip \n",
      "\n",
      "\n",
      "Accuracy: 0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, re, codecs\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.metrics.scores import accuracy\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "\n",
    "\n",
    "#-----------------------------------------\n",
    "# Use this with the latest version of nltk and Python 3 \n",
    "# In case of dispair (maybe) you can try to remove all the accents with: \n",
    "# iconv -f UTF-8 -t ascii//TRANSLIT Corpora/dist-desen.txt | tr -d \"'~^\"\n",
    "\n",
    "\n",
    "# Input\n",
    "# dist-desen, dist-teste, dist-treino (ou a versão sem acentos dos primeiros)\n",
    "# Each line has the form:\n",
    "# TAG SENTENCE\n",
    "# \n",
    "# Target: find the correct tags to the test set\n",
    "#\n",
    "# Please:\n",
    "# 1) Use the development set for development\n",
    "# 2) Use the training set as a knowledge base\n",
    "# 3) Use the test only at the end, in the final evaluation\n",
    "# 4) Baseline = edit-distance\n",
    "# 5) Evaluation measure = accuracy\n",
    "\n",
    "# What should you do:\n",
    "# (0) Run the baseline\n",
    "# (1) Try to improve results with extra pre-processing (lowercasing, stopwords, stemming,...)\n",
    "# (2) Test other similarity measures.  You can even invent you own measure. \n",
    "# (3) Test with the test file.\n",
    "#-----------------------------------------\n",
    "\n",
    "#--------------\n",
    "# Stopword to remove. Add more stopwords...\n",
    "stopWords = set(stopwords.words('portuguese'))\n",
    "\n",
    "#--------------\n",
    "# Returns the list of tags (results) and the sentences that were considered to be the closest\n",
    "# to other measures checks:\n",
    "# http://www.nltk.org/_modules/nltk/metrics/distance.html\n",
    "# Notice that there are small differences between measures. For instance, Jaccard receives sets and not lists as input:\n",
    "# (call: jaccard_distance(set(listaFrasesTreino[j]), set(listaFrasesDesenvolvimento[i]))\n",
    "# Jaccard is 0 if =\n",
    "# For some measures it is possible that you need to touch the initial value of best\n",
    "# edit-distance:\n",
    "#edit_distance(listaFrasesTreino[j], listaFrasesDesenvolvimento[i]), best = 10000, result < best\n",
    "\n",
    "def mainFunction(listaTagsTreino, listaFrasesTreino, listaFrasesDesenvolvimento):\n",
    "\tresults = []\n",
    "\tbestSentences = []\n",
    "\ti = 0\n",
    "\twhile i < len(listaFrasesDesenvolvimento):\n",
    "\t\tj = 0\n",
    "\t\tbest = 1000\n",
    "\t\ttagId = \"VOID\"\n",
    "\t\tbestSentence = \"\"\n",
    "\t\twhile j < len(listaFrasesTreino):\n",
    "\t\t\t# It is really a distance and not a similarity measure (1-similarity)\n",
    "\t\t\t#result = jaccard_distance(set(listaFrasesTreino[j].split()), set(listaFrasesDesenvolvimento[i].split()))\n",
    "            result = nlp(listaFrasesTreino[j]).similarity(nlp(listaFrasesDesenvolvimento[i]))\n",
    "\t\t\t#result = edit_distance(listaFrasesTreino[j].split(), listaFrasesDesenvolvimento[i].split())\n",
    "\t\t\t#print(result)\n",
    "\t\t\tif result < best:\n",
    "\t\t\t\ttagId = listaTagsTreino[j]\n",
    "\t\t\t\tbestSentence = listaFrasesTreino[j]\n",
    "\t\t\t\tbest = result\n",
    "\t\t\tj = j + 1\n",
    "\t\tresults.append(tagId)\n",
    "\t\tbestSentences.append(bestSentence)\n",
    "\t\ti = i + 1\n",
    "\treturn results, bestSentences\n",
    "\n",
    "def main():\n",
    "\n",
    "\t# Splits desen and train in 2: tags and sentences\n",
    "\t\n",
    "\t# Process desen\n",
    "\tlistaTagsDesenvolvimento = extrai('Corpora/dist-teste.txt',1)\n",
    "\tlistaFrasesDesenvolvimento = extrai('Corpora/dist-teste.txt', 2)\n",
    "\n",
    "\t# Process treino\n",
    "\tlistaTagsTreino = extrai('Corpora/dist-treino.txt', 1)\n",
    "\tlistaFrasesTreino = extrai('Corpora/dist-treino.txt', 2)\n",
    "\n",
    "\t#----- Pre-processing-----\n",
    "\tlistaFrasesDesenvolvimento = preProc(listaFrasesDesenvolvimento)\n",
    "\tlistaFrasesTreino = preProc(listaFrasesTreino)\n",
    "\n",
    "\t#----- Remove stopWords-----\n",
    "\tlistaFrasesDesenvolvimento = removeStopWords(listaFrasesDesenvolvimento, stopWords)\n",
    "\tlistaFrasesTreino = removeStopWords(listaFrasesTreino, stopWords)\n",
    "\n",
    "\t#----- Stemming -----\n",
    "\tlistaFrasesDesenvolvimento = tokStem(listaFrasesDesenvolvimento)\n",
    "\tlistaFrasesTreino = tokStem(listaFrasesTreino)\n",
    "\n",
    "\t# Call the main function\n",
    "\tlistaTagsEstimada = mainFunction(listaTagsTreino , listaFrasesTreino, listaFrasesDesenvolvimento)[0]\n",
    "\tfraseMaisProxima = mainFunction(listaTagsTreino , listaFrasesTreino, listaFrasesDesenvolvimento)[1]\n",
    "\n",
    "\t# Show results\n",
    "\tfor a, b, c, d in zip(listaFrasesDesenvolvimento, listaTagsEstimada, listaTagsDesenvolvimento, fraseMaisProxima):\n",
    "\t\tprint(\"Sentence to evaluate: \", a)\n",
    "\t\tprint(\"Suggested Tag: \", b)\n",
    "\t\tprint(\"Correct Tag: \", c)\n",
    "\t\tprint(\"Closest sentence: \", d, \"\\n\\n\")\n",
    "\n",
    "\t# Find accuracy\n",
    "\tprint (\"Accuracy:\", accuracy(listaTagsDesenvolvimento, listaTagsEstimada))\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Aux\n",
    "#--------------------------------------------------------\n",
    "def preProc(Lista):\n",
    "\tperguntas = []\n",
    "\tfor l in Lista:\n",
    "\t\t# ELIMINA ACENTOS\n",
    "\t\tl = re.sub(u\"ã\", 'a', l)\n",
    "\t\tl = re.sub(u\"á\", \"a\", l)\n",
    "\t\tl = re.sub(u\"à\", \"a\", l)\n",
    "\t\tl = re.sub(u\"õ\", \"o\", l)\n",
    "\t\tl = re.sub(u\"ô\", \"o\", l)\n",
    "\t\tl = re.sub(u\"ó\", \"o\", l)\n",
    "\t\tl = re.sub(u\"é\", \"e\", l)\n",
    "\t\tl = re.sub(u\"ê\", \"e\", l)\n",
    "\t\tl = re.sub(u\"í\", \"i\", l)\n",
    "\t\tl = re.sub(u\"ú\", \"u\", l)\n",
    "\t\tl = re.sub(u\"ç\", \"c\", l)\n",
    "\t\tl = re.sub(u\"Ã\", 'A', l)\n",
    "\t\tl = re.sub(u\"Á\", \"A\", l)\n",
    "\t\tl = re.sub(u\"À\", \"A\", l)\n",
    "\t\tl = re.sub(u\"Õ\", \"O\", l)\n",
    "\t\tl = re.sub(u\"Ô\", \"O\", l)\n",
    "\t\tl = re.sub(u\"Ô\", \"O\", l)\n",
    "\t\tl = re.sub(u\"Ó\", 'O', l)\n",
    "\t\tl = re.sub(u\"Í\", \"I\", l)\n",
    "\t\tl = re.sub(u\"Ú\", \"U\", l)\n",
    "\t\tl = re.sub(u\"Ç\", \"C\", l)\n",
    "\t\tl = re.sub(u\"É\", \"E\", l)\n",
    "\t\t# TUDO EM MINÚSCULAS\n",
    "\t\tl = l.lower()\n",
    "\t\t# ELIMINA PONTUAÇÃO\n",
    "\t\tl = re.sub(\"[?|\\.|!|:|,|;]\", '', l)\n",
    "\t\t# fica so com as perguntas\n",
    "\t\tl = re.sub(\"^\\w+\\t+[^\\w]\", '', l)\n",
    "\t\tperguntas.append(str(l))\n",
    "\treturn perguntas\n",
    "\n",
    "#------------------------------\n",
    "# Remove stopwords\n",
    "#------------------------------\n",
    "\n",
    "# It is case insensitive\n",
    "def removeStopWords(list, stopWordList):\n",
    "\tperguntas = []\n",
    "\tfor sentence in list:\n",
    "\t\tsentence = sentence.split()\n",
    "\t\tfrase = []\n",
    "\t\tfor word in sentence:\n",
    "\t\t\tif word.lower() not in stopWordList:\n",
    "\t\t\t\tfrase.append(word)\n",
    "\t\t\tfraseAux = ' '.join(frase)\t\n",
    "\t\tperguntas.append(fraseAux)\n",
    "\treturn perguntas\n",
    "\n",
    "#------------------------------\n",
    "# Tokenization and stemmer\n",
    "#------------------------------\n",
    "\n",
    "def tokStem(perguntas):\n",
    "\tperguntas_tok_stem = []\n",
    "\tstemmer = nltk.stem.RSLPStemmer()\n",
    "\tfor l in perguntas:\n",
    "\t\tl = nltk.word_tokenize(l)\n",
    "\t\tl1 = []\n",
    "\t\tfor word in l:\n",
    "\t\t\tword = stemmer.stem(word)\n",
    "\t\t\tl1.append(word)\n",
    "\t\tl = ' '.join(l1)\n",
    "\t\tperguntas_tok_stem.append(l)\n",
    "\treturn perguntas_tok_stem\n",
    "\n",
    "#---------------\n",
    "# Input (each line):\n",
    "# TAG SENTENCE\n",
    "# numColuna = 1 => TAG\n",
    "# numColuna = 2 => SENTENCE \n",
    "# Return:\n",
    "# Tags vector if numColuna = 1\n",
    "# Sentences vector if numColuna = 2\n",
    "#----------------\n",
    "def extrai(nameFile, numColuna):\n",
    "\tfile = open(nameFile, 'rU')\n",
    "\ttags = []\n",
    "\tsentences = []\n",
    "\tfor line in file:\n",
    "\t\tfield = re.search(r\"(\\w+[^\\s])\\t+(.+)\", line)\n",
    "\t\tif field is None:\n",
    "\t\t\tprint (\"nada\")\n",
    "\t\telse:\n",
    "\t\t\ttag = field.group(1)\n",
    "\t\t\tsentence = field.group(2)\n",
    "\t\t\ttags.append(tag)\n",
    "\t\t\tsentences.append(sentence)\n",
    "\tfile.close()\n",
    "\tif numColuna == 1:\n",
    "\t\treturn tags\n",
    "\tif numColuna == 2:\n",
    "\t\treturn sentences\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
